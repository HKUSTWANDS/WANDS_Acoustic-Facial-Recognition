# AcFace

## Introduction of this project

This project introduces a novel acoustic-based facial recognition system designed to deliver exceptional performance even under conditions where facial masks obscure parts of the face. The system is built around two primary components:

1. **Signal Processing Module**: This module processes raw acoustic signals to create precise 3D representations of faces. It is engineered to accurately capture facial features, ensuring the system's effectiveness even when traditional visual cues are partially hidden.

2. **Deep Learning Model**: This component is responsible for the recognition and differentiation of faces based on the 3D representations generated by the signal processing module. It has been meticulously trained to maintain high accuracy levels, specifically in scenarios involving facial masks.

The diagram below offers a visual overview of the system's architecture.

<div style="text-align: center;">
    <img src="https://github.com/yanbozhang003/AcFace-AE/blob/main/AcFace_structure.png" alt="Acface system structure" width="800" height="275"/>
</div>

Within this repository, we offer a comprehensive suite of tools required to deploy this system, including the signal processing algorithms essential for extracting facial spectrums and the deep learning framework for spectrum analysis and recognition. Furthermore, we have included a specially curated dataset to facilitate the evaluation of the system's performance across a diverse range of scenarios.

## Code structure

This section outlines the key components of our codebase and their functionalities. Our project is structured to ensure easy navigation and comprehension of the acoustic-based facial recognition system's implementation.

### Key Components

- `signal_processor.py`
  - **Description**: This module handles the processing of raw acoustic signals to generate 3D facial representations. It includes algorithms for signal analysis and feature extraction that are crucial for accurate face modeling, especially under obscured conditions.

- `deep_learning_model.py`
  - **Description**: Implements the deep learning framework for facial recognition. It is designed to interpret the 3D facial representations and perform the recognition process, leveraging advanced neural network techniques to ensure high accuracy.

- `dataset_loader.py`
  - **Description**: Responsible for loading and preprocessing the self-constructed dataset. It formats the data suitably for use with the signal processing module and the deep learning model, facilitating effective training and evaluation.

- `evaluation_metrics.py`
  - **Description**: Contains functions to evaluate the system's performance. This includes various metrics to assess accuracy, precision, and recall, providing insights into the system's effectiveness across different scenarios.

- `main.py`
  - **Description**: The entry point of the application. Orchestrates the workflow by integrating all modules, from processing the acoustic signals to performing facial recognition and outputting the results.


## Hardware dependencies

## Usage

### Audio signal generation and capture

### Facial Spectrum

### RD-Net 

#### Training

#### Evaluation

##### Accuracy, Precision, Recall, F1-score

##### Scalability

##### Efficiency

##### Parameter settings


