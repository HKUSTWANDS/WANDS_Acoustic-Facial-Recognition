{"cells":[{"cell_type":"markdown","source":["## Prepare tools"],"metadata":{"id":"GC_1XO9YRvNo"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aJYV5v6v3vp4","executionInfo":{"status":"ok","timestamp":1712211258782,"user_tz":-480,"elapsed":11276,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}}},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","from scipy.io import loadmat\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1712211258783,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"UOvELr4OAHKX","outputId":"37db8460-b909-49a4-f37f-71010a9d9b4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of GPU:  1 <class 'torch.device'>\n","total GPU memory:  15835660288  memory reserved:  0 memory allocated:  0\n"]}],"source":["torch.cuda.is_available()\n","\n","n_gpu = torch.cuda.device_count()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","t = torch.cuda.get_device_properties(0).total_memory\n","r = torch.cuda.memory_reserved(0)\n","a = torch.cuda.memory_allocated(0)\n","f = r-a  # free inside reserved\n","\n","print(\"Number of GPU: \", n_gpu, type(device))\n","print(\"total GPU memory: \", t, \" memory reserved: \", r, \"memory allocated: \", a)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0rWiucdSITx","executionInfo":{"status":"ok","timestamp":1712211322072,"user_tz":-480,"elapsed":63292,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"ccc5b43e-69ee-4e24-974d-07153c91e6a9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"x8JAZP3DpHxL"},"source":["## Setup dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":69956,"status":"ok","timestamp":1712211850204,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"Z_ani8bi4bhF","outputId":"3b351d08-809c-4add-9dfb-b67d1fbfdd5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["class AudioFaceDataset(Dataset):\n","    def __init__(self, data_dir, split='train', transform=None, target_transform=None):\n","        self.data_dir = data_dir\n","        self.split = split\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.all_labels = self.get_all_label_df()  # Get all labels without splitting\n","        self.labels = self.split_labels()  # Split the labels according to the specified split\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        row = self.labels.iloc[idx]\n","        label = row[\"label\"]\n","        path = row[\"path\"]\n","        data = self.read_mat_cnn(path)\n","        if self.transform:\n","            data = self.transform(data)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        identifier = path\n","\n","        return data, label, identifier\n","\n","    @staticmethod\n","    def read_mat_cnn(file):\n","        data = loadmat(file)[\"mat_concat\"]\n","        data_tmp = np.expand_dims(data, axis=0)\n","        return data_tmp.astype(np.float32)\n","\n","    def list_all_mat_files(self):\n","        all_files = [str(x.absolute()) for x in Path(self.data_dir).glob(\"**/*.mat\")]\n","        # print(f\"Found {len(all_files)} .mat files in {self.data_dir}\")\n","        return all_files\n","\n","    def convert_path_to_label(self, path_str):\n","        label_start_idx = path_str.rfind('.mat')\n","        face_label = path_str[label_start_idx-3]\n","        mask_label = path_str[label_start_idx-2]\n","        dist_label = path_str[label_start_idx-1]\n","        return \"_\".join([face_label, dist_label, mask_label])\n","\n","    def get_all_label_df(self):\n","        label_dict = {}\n","        for file in self.list_all_mat_files():\n","            label = self.convert_path_to_label(file)\n","            label_dict[file] = label\n","\n","        label_df = pd.DataFrame.from_dict(label_dict, orient=\"index\").reset_index().rename(columns={\"index\": \"path\", 0: \"label\"})\n","        return label_df\n","\n","    def split_labels(self):\n","        all_labels_shuffled = self.all_labels.sample(frac=1).reset_index(drop=True)  # Ensure reproducibility with random_state\n","        if self.split == 'train':\n","            return all_labels_shuffled.sample(frac=0.8)  # Use all data for training\n","        elif self.split == 'test':\n","            return all_labels_shuffled.sample(frac=0.2)  # Use 20% of the data for testing\n","        else:\n","            raise ValueError(\"Split must be 'train' or 'test'.\")\n","\n","# CHANGE THE FOLDER TO UNDER \"AE\"\n","data_dir = './drive/MyDrive/AcFace_AE/Dataset/samples_all'\n","\n","# Creating instances for training and testing\n","data_train = AudioFaceDataset(data_dir, split='train')\n","data_test = AudioFaceDataset(data_dir, split='test')\n","\n","# Setup DataLoader for training\n","batch_size = 128  # Specify your batch size\n","data_train_loader = DataLoader(dataset=data_train,\n","                               batch_size=batch_size,\n","                               shuffle=True,\n","                               num_workers=8)\n","\n","# Setup DataLoader for testing\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,  # Typically, we don't need to shuffle the test data\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"]},{"cell_type":"markdown","source":["## Setup model"],"metadata":{"id":"egpfoxoKUIVG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","class RDNet(nn.Module):\n","    def __init__(self, num_face=2, num_dist=2, num_mask=2):\n","        super(RDNet, self).__init__()\n","\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(1, self.in_channels, kernel_size=3, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Adding more depth with Residual Blocks\n","        self.layer1 = self._make_layer(128, stride=2)\n","        self.layer2 = self._make_layer(256, stride=2)\n","        self.layer3 = self._make_layer(512, stride=2)\n","        self.drop = nn.Dropout(p=0.3)\n","\n","        self.adaptivePool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # Increase model capacity in fully connected layers\n","        self.face_fc1 = nn.Linear(512, 2048)\n","        self.face_fc2 = nn.Linear(2048, 2048)\n","        self.face_fc3 = nn.Linear(2048, 1024)\n","        self.face_fc4 = nn.Linear(1024, 1024)\n","        self.face_fc5 = nn.Linear(1024, 1024)\n","        self.face_fc6 = nn.Linear(1024, 1024)\n","        self.face_fc7 = nn.Linear(1024, 1024)\n","        self.face_fc8 = nn.Linear(1024, 512)\n","        self.face_fc9 = nn.Linear(512, 512)\n","        self.face_fc10 = nn.Linear(512, num_face)\n","\n","        self.dist_fc1 = nn.Linear(512 + num_face, 256)\n","        self.dist_fc2 = nn.Linear(256, 256)\n","        self.dist_fc3 = nn.Linear(256, 256)\n","        self.dist_fc4 = nn.Linear(256, 128)\n","        self.dist_fc5 = nn.Linear(128, num_dist)\n","\n","        self.mask_fc1 = nn.Linear(512 + num_face, 256)\n","        self.mask_fc2 = nn.Linear(256, 256)\n","        self.mask_fc3 = nn.Linear(256, 256)\n","        self.mask_fc4 = nn.Linear(256, 128)\n","        self.mask_fc5 = nn.Linear(128, num_mask)\n","\n","    def _make_layer(self, out_channels, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","        layer = ResidualBlock(self.in_channels, out_channels, stride, downsample)\n","        self.in_channels = out_channels\n","        return layer\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.drop(x)\n","        x = self.adaptivePool(x)\n","        x_cnn_output = x.view(x.size(0), -1)\n","\n","        x_face = F.relu(self.face_fc1(x_cnn_output))\n","        x_face = F.relu(self.face_fc2(x_face))\n","        x_face = F.relu(self.face_fc3(x_face))\n","        x_face = F.relu(self.face_fc4(x_face))\n","        x_face = F.relu(self.face_fc5(x_face))\n","        x_face = F.relu(self.face_fc6(x_face))\n","        x_face = F.relu(self.face_fc7(x_face))\n","        x_face = F.relu(self.face_fc8(x_face))\n","        x_face = F.relu(self.face_fc9(x_face))\n","        x_face_output = torch.sigmoid(self.face_fc10(x_face))\n","\n","        x_dist_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_dist = F.relu(self.dist_fc1(x_dist_input))\n","        x_dist = F.relu(self.dist_fc2(x_dist))\n","        x_dist = F.relu(self.dist_fc3(x_dist))\n","        x_dist = F.relu(self.dist_fc4(x_dist))\n","        x_dist_output = torch.sigmoid(self.dist_fc5(x_dist))\n","\n","        x_mask_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_mask = F.relu(self.mask_fc1(x_mask_input))\n","        x_mask = F.relu(self.mask_fc2(x_mask))\n","        x_mask = F.relu(self.mask_fc3(x_mask))\n","        x_mask = F.relu(self.mask_fc4(x_mask))\n","        x_mask_output = torch.sigmoid(self.mask_fc5(x_mask))\n","\n","        return [x_face_output, x_dist_output, x_mask_output]\n","\n","model = RDNet().to(device)\n","\n","# Calculate total parameters and model size in bytes\n","param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n","buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n","total_size = param_size + buffer_size\n"],"metadata":{"id":"omJhUklEvn2u","executionInfo":{"status":"ok","timestamp":1712213007462,"user_tz":-480,"elapsed":800,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Model test\n","\n","\n"],"metadata":{"id":"MmsGghW9VbWf"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZSbOSLMn5Lqe","executionInfo":{"status":"ok","timestamp":1712214718759,"user_tz":-480,"elapsed":1630196,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7082047c-a59f-4e5d-bdc8-29e4e6d9b374"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Averaged accuracy for alpha = 0.0 and beta = 0.0: 87.00 %\n","\n","Averaged accuracy for alpha = 0.0 and beta = 0.01: 88.69 %\n","\n","Averaged accuracy for alpha = 0.0 and beta = 0.02: 89.59 %\n","\n","Averaged accuracy for alpha = 0.0 and beta = 0.03: 90.31 %\n","\n","Averaged accuracy for alpha = 0.0 and beta = 0.04: 88.95 %\n","\n","Averaged accuracy for alpha = 0.0 and beta = 0.05: 89.08 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.0: 90.97 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.01: 91.79 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.02: 92.68 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.03: 91.84 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.04: 91.08 %\n","\n","Averaged accuracy for alpha = 0.01 and beta = 0.05: 89.86 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.0: 93.64 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.01: 93.70 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.02: 93.35 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.03: 92.72 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.04: 91.93 %\n","\n","Averaged accuracy for alpha = 0.02 and beta = 0.05: 90.29 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.0: 94.24 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.01: 95.15 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.02: 95.81 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.03: 95.43 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.04: 94.53 %\n","\n","Averaged accuracy for alpha = 0.03 and beta = 0.05: 94.21 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.0: 93.90 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.01: 94.72 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.02: 94.25 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.03: 93.42 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.04: 92.54 %\n","\n","Averaged accuracy for alpha = 0.04 and beta = 0.05: 92.34 %\n"]}],"source":["import torch\n","import numpy as np\n","import time\n","\n","alpha_v = [0,1,2,3,4]\n","beta_v = [0,1,2,3,4,5]\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","for alpha in alpha_v:\n","    for beta in beta_v:\n","\n","      model_load_path = f'./drive/MyDrive/AcFace_AE/Model/discriminator_impact/model_alpha{alpha}_beta{beta}.pth'\n","      model.load_state_dict(torch.load(model_load_path))\n","\n","      model.eval()\n","\n","      acc_list = []\n","      cost_list = []\n","      incorrect_samples = []\n","      predictions = []\n","      true_labels = []\n","\n","      for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","          face_Y, dist_Y, mask_Y = [], [], []\n","          for Y_i in test_Y:\n","              underline_idx = Y_i.find(\"_\")\n","              face_Y.append(int(Y_i[underline_idx-1]))\n","              dist_Y.append(int(Y_i[underline_idx+1]))\n","              mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","          X = test_X.to(device)\n","          face_Y = torch.LongTensor(face_Y).to(device)\n","          dist_Y = torch.LongTensor(dist_Y).to(device)\n","          mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","          with torch.no_grad():\n","              output = model(X)\n","\n","              cost_face = criterion(output[0], face_Y)\n","              cost_dist = criterion(output[1], dist_Y)\n","              cost_mask = criterion(output[2], mask_Y)\n","              cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","              accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","              acc_list.append(accuracy)\n","              cost_list.append(cost.item())\n","\n","              predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","              true_labels.extend(face_Y.cpu().numpy())\n","\n","              # print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","              incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","              incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","              incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","      if acc_list:  # Check if acc_list is not empty\n","          print('\\nAveraged accuracy for alpha = ' + str(alpha/100) + ' and beta = ' + str(beta/100) + ': ' + '{:2.2f}'.format(np.mean(acc_list) * 100) + ' %')\n","      else:\n","          raise Exception(\"\\nNo valid accuracy computations were performed.\")\n","\n","      # if cost_list:  # Check if cost_list is not empty\n","      #     print('Overall Cost: {:2.2f}'.format(np.mean(cost_list)))\n","      # else:\n","      #     raise Exception(\"\\nNo valid cost computations were performed.\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}