{"cells":[{"cell_type":"markdown","source":["## Prepare tools"],"metadata":{"id":"GC_1XO9YRvNo"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aJYV5v6v3vp4","executionInfo":{"status":"ok","timestamp":1712211791139,"user_tz":-480,"elapsed":6743,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}}},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","from scipy.io import loadmat\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1712211791139,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"UOvELr4OAHKX","outputId":"d96d056f-e231-4c69-d35b-d451e19e70d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of GPU:  1 <class 'torch.device'>\n","total GPU memory:  15835660288  memory reserved:  0 memory allocated:  0\n"]}],"source":["torch.cuda.is_available()\n","\n","n_gpu = torch.cuda.device_count()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","t = torch.cuda.get_device_properties(0).total_memory\n","r = torch.cuda.memory_reserved(0)\n","a = torch.cuda.memory_allocated(0)\n","f = r-a  # free inside reserved\n","\n","print(\"Number of GPU: \", n_gpu, type(device))\n","print(\"total GPU memory: \", t, \" memory reserved: \", r, \"memory allocated: \", a)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0rWiucdSITx","executionInfo":{"status":"ok","timestamp":1712211809780,"user_tz":-480,"elapsed":18643,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"669b93dd-ec20-472b-ebbb-bb32dad1b5b6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Setup model"],"metadata":{"id":"egpfoxoKUIVG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","class RDNet(nn.Module):\n","    def __init__(self, num_face=2, num_dist=2, num_mask=2):\n","        super(RDNet, self).__init__()\n","\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(1, self.in_channels, kernel_size=3, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Adding more depth with Residual Blocks\n","        self.layer1 = self._make_layer(128, stride=2)\n","        self.layer2 = self._make_layer(256, stride=2)\n","        self.layer3 = self._make_layer(512, stride=2)\n","        self.drop = nn.Dropout(p=0.3)\n","\n","        self.adaptivePool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # Increase model capacity in fully connected layers\n","        self.face_fc1 = nn.Linear(512, 2048)\n","        self.face_fc2 = nn.Linear(2048, 2048)\n","        self.face_fc3 = nn.Linear(2048, 1024)\n","        self.face_fc4 = nn.Linear(1024, 1024)\n","        self.face_fc5 = nn.Linear(1024, 1024)\n","        self.face_fc6 = nn.Linear(1024, 1024)\n","        self.face_fc7 = nn.Linear(1024, 1024)\n","        self.face_fc8 = nn.Linear(1024, 512)\n","        self.face_fc9 = nn.Linear(512, 512)\n","        self.face_fc10 = nn.Linear(512, num_face)\n","\n","        self.dist_fc1 = nn.Linear(512 + num_face, 256)\n","        self.dist_fc2 = nn.Linear(256, 256)\n","        self.dist_fc3 = nn.Linear(256, 256)\n","        self.dist_fc4 = nn.Linear(256, 128)\n","        self.dist_fc5 = nn.Linear(128, num_dist)\n","\n","        self.mask_fc1 = nn.Linear(512 + num_face, 256)\n","        self.mask_fc2 = nn.Linear(256, 256)\n","        self.mask_fc3 = nn.Linear(256, 256)\n","        self.mask_fc4 = nn.Linear(256, 128)\n","        self.mask_fc5 = nn.Linear(128, num_mask)\n","\n","    def _make_layer(self, out_channels, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","        layer = ResidualBlock(self.in_channels, out_channels, stride, downsample)\n","        self.in_channels = out_channels\n","        return layer\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.drop(x)\n","        x = self.adaptivePool(x)\n","        x_cnn_output = x.view(x.size(0), -1)\n","\n","        x_face = F.relu(self.face_fc1(x_cnn_output))\n","        x_face = F.relu(self.face_fc2(x_face))\n","        x_face = F.relu(self.face_fc3(x_face))\n","        x_face = F.relu(self.face_fc4(x_face))\n","        x_face = F.relu(self.face_fc5(x_face))\n","        x_face = F.relu(self.face_fc6(x_face))\n","        x_face = F.relu(self.face_fc7(x_face))\n","        x_face = F.relu(self.face_fc8(x_face))\n","        x_face = F.relu(self.face_fc9(x_face))\n","        x_face_output = torch.sigmoid(self.face_fc10(x_face))\n","\n","        x_dist_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_dist = F.relu(self.dist_fc1(x_dist_input))\n","        x_dist = F.relu(self.dist_fc2(x_dist))\n","        x_dist = F.relu(self.dist_fc3(x_dist))\n","        x_dist = F.relu(self.dist_fc4(x_dist))\n","        x_dist_output = torch.sigmoid(self.dist_fc5(x_dist))\n","\n","        x_mask_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_mask = F.relu(self.mask_fc1(x_mask_input))\n","        x_mask = F.relu(self.mask_fc2(x_mask))\n","        x_mask = F.relu(self.mask_fc3(x_mask))\n","        x_mask = F.relu(self.mask_fc4(x_mask))\n","        x_mask_output = torch.sigmoid(self.mask_fc5(x_mask))\n","\n","        return [x_face_output, x_dist_output, x_mask_output]\n","\n","model = RDNet().to(device)\n","\n","# Calculate total parameters and model size in bytes\n","param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n","buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n","total_size = param_size + buffer_size\n","\n","# Convert bytes to megabytes (MB)\n","size_in_mb = total_size / (1024 ** 2)\n","\n","print(f'Total parameters: {sum(p.numel() for p in model.parameters())}')\n","print(f'Model size: {size_in_mb:.3f} MB')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omJhUklEvn2u","executionInfo":{"status":"ok","timestamp":1712211810146,"user_tz":-480,"elapsed":369,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"1b1dea01-ace4-4192-abb3-e2686d45fd2a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 17748230\n","Model size: 67.725 MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"x8JAZP3DpHxL"},"source":["## Setup dataloader"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1712211810146,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"Z_ani8bi4bhF"},"outputs":[],"source":["class AudioFaceDataset(Dataset):\n","    def __init__(self, data_dir, split='train', transform=None, target_transform=None):\n","        self.data_dir = data_dir\n","        self.split = split\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.all_labels = self.get_all_label_df()  # Get all labels without splitting\n","        self.labels = self.split_labels()  # Split the labels according to the specified split\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        row = self.labels.iloc[idx]\n","        label = row[\"label\"]\n","        path = row[\"path\"]\n","        data = self.read_mat_cnn(path)\n","        if self.transform:\n","            data = self.transform(data)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        identifier = path\n","\n","        return data, label, identifier\n","\n","    @staticmethod\n","    def read_mat_cnn(file):\n","        data = loadmat(file)[\"mat_concat\"]\n","        data_tmp = np.expand_dims(data, axis=0)\n","        return data_tmp.astype(np.float32)\n","\n","    def list_all_mat_files(self):\n","        all_files = [str(x.absolute()) for x in Path(self.data_dir).glob(\"**/*.mat\")]\n","        # print(f\"Found {len(all_files)} .mat files in {self.data_dir}\")\n","        return all_files\n","\n","    def convert_path_to_label(self, path_str):\n","        label_start_idx = path_str.rfind('.mat')\n","        face_label = path_str[label_start_idx-3]\n","        mask_label = path_str[label_start_idx-2]\n","        dist_label = path_str[label_start_idx-1]\n","        return \"_\".join([face_label, dist_label, mask_label])\n","\n","    def get_all_label_df(self):\n","        label_dict = {}\n","        for file in self.list_all_mat_files():\n","            label = self.convert_path_to_label(file)\n","            label_dict[file] = label\n","\n","        label_df = pd.DataFrame.from_dict(label_dict, orient=\"index\").reset_index().rename(columns={\"index\": \"path\", 0: \"label\"})\n","        return label_df\n","\n","    def split_labels(self):\n","        all_labels_shuffled = self.all_labels.sample(frac=1).reset_index(drop=True)  # Ensure reproducibility with random_state\n","        if self.split == 'train':\n","            return all_labels_shuffled.sample(frac=0.8)  # Use all data for training\n","        elif self.split == 'test':\n","            return all_labels_shuffled.sample(frac=0.5)\n","        else:\n","            raise ValueError(\"Split must be 'train' or 'test'.\")\n","\n"]},{"cell_type":"markdown","source":["## Model test - NCH14\n","\n","\n"],"metadata":{"id":"MmsGghW9VbWf"}},{"cell_type":"code","source":["data_dir = './drive/MyDrive/AcFace_AE/Dataset/Channel/NCH14/samples'\n","\n","# Creating instances for training and testing\n","data_test = AudioFaceDataset(data_dir, split='test')\n","\n","# Setup DataLoader for training\n","batch_size = 64\n","\n","# Setup DataLoader for testing\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,  # Typically, we don't need to shuffle the test data\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-t0HiitqItV","executionInfo":{"status":"ok","timestamp":1712211856300,"user_tz":-480,"elapsed":46156,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"0ac372d9-81c8-44ce-aebc-3894ce6abdae"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ZSbOSLMn5Lqe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712212143256,"user_tz":-480,"elapsed":286960,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"33ab5c8c-139a-4b22-ea3f-cedb461a9015"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 93.75 %\n","Batch 1 averaged accuracy: 96.88 %\n","Batch 2 averaged accuracy: 90.62 %\n","Batch 3 averaged accuracy: 93.75 %\n","Batch 4 averaged accuracy: 92.19 %\n","Batch 5 averaged accuracy: 96.88 %\n","Batch 6 averaged accuracy: 96.88 %\n","Batch 7 averaged accuracy: 95.31 %\n","Batch 8 averaged accuracy: 95.31 %\n","Batch 9 averaged accuracy: 95.31 %\n","Batch 10 averaged accuracy: 95.31 %\n","Batch 11 averaged accuracy: 95.31 %\n","Batch 12 averaged accuracy: 95.31 %\n","Batch 13 averaged accuracy: 92.19 %\n","Batch 14 averaged accuracy: 98.44 %\n","Batch 15 averaged accuracy: 100.00 %\n","Batch 16 averaged accuracy: 96.88 %\n","Batch 17 averaged accuracy: 92.19 %\n","Batch 18 averaged accuracy: 92.19 %\n","Batch 19 averaged accuracy: 98.44 %\n","Batch 20 averaged accuracy: 93.75 %\n","Batch 21 averaged accuracy: 90.62 %\n","Batch 22 averaged accuracy: 96.88 %\n","Batch 23 averaged accuracy: 96.88 %\n","Batch 24 averaged accuracy: 96.88 %\n","Batch 25 averaged accuracy: 95.31 %\n","Batch 26 averaged accuracy: 96.88 %\n","Batch 27 averaged accuracy: 96.88 %\n","Batch 28 averaged accuracy: 89.06 %\n","Batch 29 averaged accuracy: 93.75 %\n","Batch 30 averaged accuracy: 93.75 %\n","Batch 31 averaged accuracy: 95.31 %\n","Batch 32 averaged accuracy: 92.19 %\n","Batch 33 averaged accuracy: 90.62 %\n","Batch 34 averaged accuracy: 96.88 %\n","Batch 35 averaged accuracy: 96.88 %\n","Batch 36 averaged accuracy: 89.06 %\n","Batch 37 averaged accuracy: 96.88 %\n","Batch 38 averaged accuracy: 95.31 %\n","Batch 39 averaged accuracy: 93.75 %\n","Batch 40 averaged accuracy: 95.31 %\n","Batch 41 averaged accuracy: 90.62 %\n","Batch 42 averaged accuracy: 95.31 %\n","Batch 43 averaged accuracy: 98.44 %\n","Batch 44 averaged accuracy: 95.31 %\n","Batch 45 averaged accuracy: 96.88 %\n","Batch 46 averaged accuracy: 89.06 %\n","Batch 47 averaged accuracy: 92.19 %\n","Batch 48 averaged accuracy: 96.88 %\n","Batch 49 averaged accuracy: 93.75 %\n","Batch 50 averaged accuracy: 90.62 %\n","Batch 51 averaged accuracy: 93.75 %\n","Batch 52 averaged accuracy: 93.75 %\n","Batch 53 averaged accuracy: 93.75 %\n","Batch 54 averaged accuracy: 90.62 %\n","Batch 55 averaged accuracy: 89.06 %\n","Batch 56 averaged accuracy: 93.75 %\n","\n","Overall Accuracy: 94.38 %\n","Overall Cost: 0.35\n"]}],"source":["import torch\n","import numpy as np\n","import time\n","\n","model_load_path = './drive/MyDrive/AcFace_AE/Model/channel/NCH14_trained.pth'  # The path where your model is saved\n","model.load_state_dict(torch.load(model_load_path))\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")\n","\n"]},{"cell_type":"markdown","source":["## Model test - NCH 12"],"metadata":{"id":"8Vr6lzaBrj2v"}},{"cell_type":"code","source":["data_dir = './drive/MyDrive/AcFace_AE/Dataset/Channel/NCH12/samples'\n","\n","# Creating instances for training and testing\n","data_test = AudioFaceDataset(data_dir, split='test')\n","\n","# Setup DataLoader for training\n","batch_size = 64\n","\n","# Setup DataLoader for testing\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,  # Typically, we don't need to shuffle the test data\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712212184619,"user_tz":-480,"elapsed":41368,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"d548bca6-cebb-474a-a738-2302062e1ac0","id":"vbcjkeUs8rHv"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","model_load_path = './drive/MyDrive/AcFace_AE/Model/channel/NCH12_trained.pth'  # The path where your model is saved\n","model.load_state_dict(torch.load(model_load_path))\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYmWVfQPbOM3","executionInfo":{"status":"ok","timestamp":1712212534405,"user_tz":-480,"elapsed":349790,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"2b4f6956-0100-49c9-ecb1-263a9f5ec7c8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 93.75 %\n","Batch 1 averaged accuracy: 93.75 %\n","Batch 2 averaged accuracy: 95.31 %\n","Batch 3 averaged accuracy: 93.75 %\n","Batch 4 averaged accuracy: 87.50 %\n","Batch 5 averaged accuracy: 90.62 %\n","Batch 6 averaged accuracy: 87.50 %\n","Batch 7 averaged accuracy: 95.31 %\n","Batch 8 averaged accuracy: 85.94 %\n","Batch 9 averaged accuracy: 96.88 %\n","Batch 10 averaged accuracy: 85.94 %\n","Batch 11 averaged accuracy: 93.75 %\n","Batch 12 averaged accuracy: 90.62 %\n","Batch 13 averaged accuracy: 92.19 %\n","Batch 14 averaged accuracy: 95.31 %\n","Batch 15 averaged accuracy: 90.62 %\n","Batch 16 averaged accuracy: 93.75 %\n","Batch 17 averaged accuracy: 92.19 %\n","Batch 18 averaged accuracy: 93.75 %\n","Batch 19 averaged accuracy: 90.62 %\n","Batch 20 averaged accuracy: 95.31 %\n","Batch 21 averaged accuracy: 98.44 %\n","Batch 22 averaged accuracy: 95.31 %\n","Batch 23 averaged accuracy: 93.75 %\n","Batch 24 averaged accuracy: 98.44 %\n","Batch 25 averaged accuracy: 89.06 %\n","Batch 26 averaged accuracy: 90.62 %\n","Batch 27 averaged accuracy: 95.31 %\n","Batch 28 averaged accuracy: 92.19 %\n","Batch 29 averaged accuracy: 92.19 %\n","Batch 30 averaged accuracy: 95.31 %\n","Batch 31 averaged accuracy: 93.75 %\n","Batch 32 averaged accuracy: 90.62 %\n","Batch 33 averaged accuracy: 90.62 %\n","Batch 34 averaged accuracy: 92.19 %\n","Batch 35 averaged accuracy: 93.75 %\n","Batch 36 averaged accuracy: 96.88 %\n","Batch 37 averaged accuracy: 87.50 %\n","Batch 38 averaged accuracy: 93.75 %\n","Batch 39 averaged accuracy: 90.62 %\n","Batch 40 averaged accuracy: 96.88 %\n","Batch 41 averaged accuracy: 93.75 %\n","Batch 42 averaged accuracy: 84.38 %\n","Batch 43 averaged accuracy: 95.31 %\n","Batch 44 averaged accuracy: 89.06 %\n","Batch 45 averaged accuracy: 92.19 %\n","Batch 46 averaged accuracy: 92.19 %\n","Batch 47 averaged accuracy: 95.31 %\n","Batch 48 averaged accuracy: 93.75 %\n","Batch 49 averaged accuracy: 93.75 %\n","Batch 50 averaged accuracy: 95.31 %\n","Batch 51 averaged accuracy: 92.19 %\n","Batch 52 averaged accuracy: 92.19 %\n","Batch 53 averaged accuracy: 90.62 %\n","Batch 54 averaged accuracy: 95.31 %\n","Batch 55 averaged accuracy: 92.19 %\n","Batch 56 averaged accuracy: 62.50 %\n","\n","Overall Accuracy: 92.13 %\n","Overall Cost: 0.37\n"]}]},{"cell_type":"markdown","source":["## Model test - NCH10"],"metadata":{"id":"5wMxRxH_o3Nf"}},{"cell_type":"code","source":["data_dir = './drive/MyDrive/AcFace_AE/Dataset/Channel/NCH10/samples'\n","\n","# Creating instances for training and testing\n","data_test = AudioFaceDataset(data_dir, split='test')\n","\n","# Setup DataLoader for training\n","batch_size = 64\n","\n","# Setup DataLoader for testing\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,  # Typically, we don't need to shuffle the test data\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712212582570,"user_tz":-480,"elapsed":48172,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"a0c72d42-488c-44a0-e429-f8387c8da2a2","id":"eaY-rdjmoyqQ"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","model_load_path = './drive/MyDrive/AcFace_AE/Model/channel/NCH10_trained.pth'  # The path where your model is saved\n","model.load_state_dict(torch.load(model_load_path))\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","# Assuming your model, criterion, and device are already defined\n","model.eval()  # Set the model to evaluation mode\n","\n","acc_list = []\n","cost_list = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):  # Adjusted to unpack sample_ids\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():  # Ensure no gradients are calculated\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        # cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask  # Modified to use addition\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        # Print accuracy for the current batch\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","if acc_list:  # Check if acc_list is not empty to avoid division by zero\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    print(\"\\nNo valid accuracy computations were performed.\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tb08zAfnpWDo","executionInfo":{"status":"ok","timestamp":1712212829551,"user_tz":-480,"elapsed":246992,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"2ce45d6c-d2ce-4018-c03e-bd5d185c3a29"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 Accuracy: 84.38 %\n","Batch 1 Accuracy: 70.31 %\n","Batch 2 Accuracy: 79.69 %\n","Batch 3 Accuracy: 81.25 %\n","Batch 4 Accuracy: 78.12 %\n","Batch 5 Accuracy: 87.50 %\n","Batch 6 Accuracy: 85.94 %\n","Batch 7 Accuracy: 82.81 %\n","Batch 8 Accuracy: 85.94 %\n","Batch 9 Accuracy: 75.00 %\n","Batch 10 Accuracy: 84.38 %\n","Batch 11 Accuracy: 78.12 %\n","Batch 12 Accuracy: 76.56 %\n","Batch 13 Accuracy: 82.81 %\n","Batch 14 Accuracy: 78.12 %\n","Batch 15 Accuracy: 85.94 %\n","Batch 16 Accuracy: 81.25 %\n","Batch 17 Accuracy: 71.88 %\n","Batch 18 Accuracy: 81.25 %\n","Batch 19 Accuracy: 81.25 %\n","Batch 20 Accuracy: 81.25 %\n","Batch 21 Accuracy: 78.12 %\n","Batch 22 Accuracy: 81.25 %\n","Batch 23 Accuracy: 76.56 %\n","Batch 24 Accuracy: 84.38 %\n","Batch 25 Accuracy: 78.12 %\n","Batch 26 Accuracy: 75.00 %\n","Batch 27 Accuracy: 82.81 %\n","Batch 28 Accuracy: 68.75 %\n","Batch 29 Accuracy: 78.12 %\n","Batch 30 Accuracy: 75.00 %\n","Batch 31 Accuracy: 85.94 %\n","Batch 32 Accuracy: 76.56 %\n","Batch 33 Accuracy: 70.31 %\n","Batch 34 Accuracy: 79.69 %\n","Batch 35 Accuracy: 79.69 %\n","Batch 36 Accuracy: 70.31 %\n","Batch 37 Accuracy: 76.56 %\n","Batch 38 Accuracy: 73.44 %\n","Batch 39 Accuracy: 84.38 %\n","Batch 40 Accuracy: 82.81 %\n","Batch 41 Accuracy: 79.69 %\n","Batch 42 Accuracy: 82.81 %\n","Batch 43 Accuracy: 81.25 %\n","Batch 44 Accuracy: 81.25 %\n","Batch 45 Accuracy: 81.25 %\n","Batch 46 Accuracy: 65.62 %\n","Batch 47 Accuracy: 76.56 %\n","Batch 48 Accuracy: 85.94 %\n","Batch 49 Accuracy: 82.81 %\n","Batch 50 Accuracy: 82.81 %\n","Batch 51 Accuracy: 84.38 %\n","Batch 52 Accuracy: 75.00 %\n","Batch 53 Accuracy: 85.94 %\n","Batch 54 Accuracy: 68.75 %\n","Batch 55 Accuracy: 78.12 %\n","Batch 56 Accuracy: 87.50 %\n","\n","Overall Accuracy: 79.50 %\n","Overall Cost: 0.50\n"]}]},{"cell_type":"markdown","source":["## Model test - NCH 8"],"metadata":{"id":"H-_L5JbqqtXs"}},{"cell_type":"code","source":["data_dir = './drive/MyDrive/AcFace_AE/Dataset/Channel/NCH8/samples'\n","\n","# Creating instances for training and testing\n","data_test = AudioFaceDataset(data_dir, split='test')\n","\n","# Setup DataLoader for training\n","batch_size = 64\n","\n","# Setup DataLoader for testing\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,  # Typically, we don't need to shuffle the test data\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIuUVdhXq53r","executionInfo":{"status":"ok","timestamp":1712212877630,"user_tz":-480,"elapsed":48084,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"12a668a7-a283-4b35-a1a1-ec48fddf1d03"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","model_load_path = './drive/MyDrive/AcFace_AE/Model/channel/NCH8_trained.pth'  # The path where your model is saved\n","model.load_state_dict(torch.load(model_load_path))\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","# Assuming your model, criterion, and device are already defined\n","model.eval()  # Set the model to evaluation mode\n","\n","acc_list = []\n","cost_list = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):  # Adjusted to unpack sample_ids\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():  # Ensure no gradients are calculated\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        # cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask  # Modified to use addition\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        # Print accuracy for the current batch\n","        print(f'Batch {i} Accuracy: {accuracy*100:.2f} %')\n","\n","\n","if acc_list:  # Check if acc_list is not empty to avoid division by zero\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    print(\"\\nNo valid accuracy computations were performed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712213190273,"user_tz":-480,"elapsed":312670,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"4e43f4be-52d2-4d05-ff16-e08dc52102c5","id":"OHy7gpiFg7Ik"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 Accuracy: 70.31 %\n","Batch 1 Accuracy: 64.06 %\n","Batch 2 Accuracy: 73.44 %\n","Batch 3 Accuracy: 65.62 %\n","Batch 4 Accuracy: 67.19 %\n","Batch 5 Accuracy: 75.00 %\n","Batch 6 Accuracy: 70.31 %\n","Batch 7 Accuracy: 59.38 %\n","Batch 8 Accuracy: 62.50 %\n","Batch 9 Accuracy: 75.00 %\n","Batch 10 Accuracy: 56.25 %\n","Batch 11 Accuracy: 67.19 %\n","Batch 12 Accuracy: 65.62 %\n","Batch 13 Accuracy: 65.62 %\n","Batch 14 Accuracy: 67.19 %\n","Batch 15 Accuracy: 68.75 %\n","Batch 16 Accuracy: 84.38 %\n","Batch 17 Accuracy: 60.94 %\n","Batch 18 Accuracy: 67.19 %\n","Batch 19 Accuracy: 64.06 %\n","Batch 20 Accuracy: 70.31 %\n","Batch 21 Accuracy: 71.88 %\n","Batch 22 Accuracy: 71.88 %\n","Batch 23 Accuracy: 65.62 %\n","Batch 24 Accuracy: 68.75 %\n","Batch 25 Accuracy: 67.19 %\n","Batch 26 Accuracy: 59.38 %\n","Batch 27 Accuracy: 64.06 %\n","Batch 28 Accuracy: 65.62 %\n","Batch 29 Accuracy: 73.44 %\n","Batch 30 Accuracy: 67.19 %\n","Batch 31 Accuracy: 57.81 %\n","Batch 32 Accuracy: 62.50 %\n","Batch 33 Accuracy: 70.31 %\n","Batch 34 Accuracy: 70.31 %\n","Batch 35 Accuracy: 62.50 %\n","Batch 36 Accuracy: 65.62 %\n","Batch 37 Accuracy: 76.56 %\n","Batch 38 Accuracy: 68.75 %\n","Batch 39 Accuracy: 62.50 %\n","Batch 40 Accuracy: 73.44 %\n","Batch 41 Accuracy: 68.75 %\n","Batch 42 Accuracy: 62.50 %\n","Batch 43 Accuracy: 65.62 %\n","Batch 44 Accuracy: 68.75 %\n","Batch 45 Accuracy: 70.31 %\n","Batch 46 Accuracy: 71.88 %\n","Batch 47 Accuracy: 51.56 %\n","Batch 48 Accuracy: 67.19 %\n","Batch 49 Accuracy: 60.94 %\n","Batch 50 Accuracy: 68.75 %\n","Batch 51 Accuracy: 71.88 %\n","Batch 52 Accuracy: 60.94 %\n","Batch 53 Accuracy: 59.38 %\n","Batch 54 Accuracy: 68.75 %\n","Batch 55 Accuracy: 71.88 %\n","Batch 56 Accuracy: 87.50 %\n","\n","Overall Accuracy: 67.41 %\n","Overall Cost: 0.62\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}