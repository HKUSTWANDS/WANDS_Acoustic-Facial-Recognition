{"cells":[{"cell_type":"markdown","source":["## Prepare tools"],"metadata":{"id":"GC_1XO9YRvNo"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aJYV5v6v3vp4","executionInfo":{"status":"ok","timestamp":1712311056821,"user_tz":-480,"elapsed":6051,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}}},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init\n","from scipy.io import loadmat\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1712311056821,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"UOvELr4OAHKX","outputId":"411d1a05-04cf-4efb-e406-1ee841e0b2e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of GPU:  1 <class 'torch.device'>\n","total GPU memory:  15835660288  memory reserved:  0 memory allocated:  0\n"]}],"source":["torch.cuda.is_available()\n","\n","n_gpu = torch.cuda.device_count()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","t = torch.cuda.get_device_properties(0).total_memory\n","r = torch.cuda.memory_reserved(0)\n","a = torch.cuda.memory_allocated(0)\n","f = r-a  # free inside reserved\n","\n","print(\"Number of GPU: \", n_gpu, type(device))\n","print(\"total GPU memory: \", t, \" memory reserved: \", r, \"memory allocated: \", a)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0rWiucdSITx","executionInfo":{"status":"ok","timestamp":1712311083638,"user_tz":-480,"elapsed":26827,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"dae68ef2-5cde-4f42-8c01-b795b9a218cd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Setup model"],"metadata":{"id":"egpfoxoKUIVG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.downsample = downsample\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        if self.downsample:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","class RDNet(nn.Module):\n","    def __init__(self, num_face=2, num_dist=2, num_mask=2):\n","        super(RDNet, self).__init__()\n","\n","        self.in_channels = 64\n","        self.conv1 = nn.Conv2d(1, self.in_channels, kernel_size=3, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(self.in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Adding more depth with Residual Blocks\n","        self.layer1 = self._make_layer(128, stride=2)\n","        self.layer2 = self._make_layer(256, stride=2)\n","        self.layer3 = self._make_layer(512, stride=2)\n","        self.drop = nn.Dropout(p=0.3)\n","\n","        self.adaptivePool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","        # Increase model capacity in fully connected layers\n","        self.face_fc1 = nn.Linear(512, 2048)\n","        self.face_fc2 = nn.Linear(2048, 2048)\n","        self.face_fc3 = nn.Linear(2048, 1024)\n","        self.face_fc4 = nn.Linear(1024, 1024)\n","        self.face_fc5 = nn.Linear(1024, 1024)\n","        self.face_fc6 = nn.Linear(1024, 1024)\n","        self.face_fc7 = nn.Linear(1024, 1024)\n","        self.face_fc8 = nn.Linear(1024, 512)\n","        self.face_fc9 = nn.Linear(512, 512)\n","        self.face_fc10 = nn.Linear(512, num_face)\n","\n","        self.dist_fc1 = nn.Linear(512 + num_face, 256)\n","        self.dist_fc2 = nn.Linear(256, 256)\n","        self.dist_fc3 = nn.Linear(256, 256)\n","        self.dist_fc4 = nn.Linear(256, 128)\n","        self.dist_fc5 = nn.Linear(128, num_dist)\n","\n","        self.mask_fc1 = nn.Linear(512 + num_face, 256)\n","        self.mask_fc2 = nn.Linear(256, 256)\n","        self.mask_fc3 = nn.Linear(256, 256)\n","        self.mask_fc4 = nn.Linear(256, 128)\n","        self.mask_fc5 = nn.Linear(128, num_mask)\n","\n","    def _make_layer(self, out_channels, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_channels != out_channels:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","        layer = ResidualBlock(self.in_channels, out_channels, stride, downsample)\n","        self.in_channels = out_channels\n","        return layer\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        x = self.drop(x)\n","        x = self.adaptivePool(x)\n","        x_cnn_output = x.view(x.size(0), -1)\n","\n","        x_face = F.relu(self.face_fc1(x_cnn_output))\n","        x_face = F.relu(self.face_fc2(x_face))\n","        x_face = F.relu(self.face_fc3(x_face))\n","        x_face = F.relu(self.face_fc4(x_face))\n","        x_face = F.relu(self.face_fc5(x_face))\n","        x_face = F.relu(self.face_fc6(x_face))\n","        x_face = F.relu(self.face_fc7(x_face))\n","        x_face = F.relu(self.face_fc8(x_face))\n","        x_face = F.relu(self.face_fc9(x_face))\n","        x_face_output = torch.sigmoid(self.face_fc10(x_face))\n","\n","        x_dist_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_dist = F.relu(self.dist_fc1(x_dist_input))\n","        x_dist = F.relu(self.dist_fc2(x_dist))\n","        x_dist = F.relu(self.dist_fc3(x_dist))\n","        x_dist = F.relu(self.dist_fc4(x_dist))\n","        x_dist_output = torch.sigmoid(self.dist_fc5(x_dist))\n","\n","        x_mask_input = torch.cat((x_cnn_output, x_face_output), 1)\n","        x_mask = F.relu(self.mask_fc1(x_mask_input))\n","        x_mask = F.relu(self.mask_fc2(x_mask))\n","        x_mask = F.relu(self.mask_fc3(x_mask))\n","        x_mask = F.relu(self.mask_fc4(x_mask))\n","        x_mask_output = torch.sigmoid(self.mask_fc5(x_mask))\n","\n","        return [x_face_output, x_dist_output, x_mask_output]\n","\n","model = RDNet().to(device)\n","\n","# Calculate total parameters and model size in bytes\n","param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n","buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n","total_size = param_size + buffer_size\n"],"metadata":{"id":"omJhUklEvn2u","executionInfo":{"status":"ok","timestamp":1712311084172,"user_tz":-480,"elapsed":536,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Load model"],"metadata":{"id":"6cr8DpInWPB6"}},{"cell_type":"code","source":["model_load_path = './drive/MyDrive/AcFace_AE/RD-Net/Model/scalability/model_nu10.pth'  # The path where your model is saved\n","model.load_state_dict(torch.load(model_load_path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__12s3622aay","executionInfo":{"status":"ok","timestamp":1712311086337,"user_tz":-480,"elapsed":2166,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"557d87de-d91f-4a89-cbf7-32ea6a2502c4"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"x8JAZP3DpHxL"},"source":["## Setup dataloader"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1712311086337,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"},"user_tz":-480},"id":"Z_ani8bi4bhF"},"outputs":[],"source":["class AudioFaceDataset(Dataset):\n","    def __init__(self, data_dir, split='train', transform=None, target_transform=None):\n","        self.data_dir = data_dir\n","        self.split = split\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.all_labels = self.get_all_label_df()  # Get all labels without splitting\n","        self.labels = self.split_labels()  # Split the labels according to the specified split\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        row = self.labels.iloc[idx]\n","        label = row[\"label\"]\n","        path = row[\"path\"]\n","        data = self.read_mat_cnn(path)\n","        if self.transform:\n","            data = self.transform(data)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","\n","        identifier = path\n","\n","        return data, label, identifier\n","\n","    @staticmethod\n","    def read_mat_cnn(file):\n","        data = loadmat(file)[\"mat_concat\"]\n","        data_tmp = np.expand_dims(data, axis=0)\n","        return data_tmp.astype(np.float32)\n","\n","    def list_all_mat_files(self):\n","        all_files = [str(x.absolute()) for x in Path(self.data_dir).glob(\"**/*.mat\")]\n","        # print(f\"Found {len(all_files)} .mat files in {self.data_dir}\")\n","        return all_files\n","\n","    def convert_path_to_label(self, path_str):\n","        label_start_idx = path_str.rfind('.mat')\n","        face_label = path_str[label_start_idx-3]\n","        mask_label = path_str[label_start_idx-2]\n","        dist_label = path_str[label_start_idx-1]\n","        return \"_\".join([face_label, dist_label, mask_label])\n","\n","    def get_all_label_df(self):\n","        label_dict = {}\n","        for file in self.list_all_mat_files():\n","            label = self.convert_path_to_label(file)\n","            label_dict[file] = label\n","\n","        label_df = pd.DataFrame.from_dict(label_dict, orient=\"index\").reset_index().rename(columns={\"index\": \"path\", 0: \"label\"})\n","        return label_df\n","\n","    def split_labels(self):\n","        all_labels_shuffled = self.all_labels.sample(frac=1).reset_index(drop=True)  # Ensure reproducibility with random_state\n","        if self.split == 'train':\n","            return all_labels_shuffled.sample(frac=0.8)  # Use all data for training\n","        elif self.split == 'test':\n","            return all_labels_shuffled.sample(frac=1)  # Use 20% of the data for testing\n","        else:\n","            raise ValueError(\"Split must be 'train' or 'test'.\")\n"]},{"cell_type":"markdown","source":["## Load data and test - 10 users"],"metadata":{"id":"hcdhjy0pWa3U"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU10'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6S4YpvGWYqJ","executionInfo":{"status":"ok","timestamp":1712311109402,"user_tz":-480,"elapsed":23067,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"ec4b50b2-4c21-4c41-bf6a-d46ca8a8db0d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCXQJFzAXey8","executionInfo":{"status":"ok","timestamp":1712311186091,"user_tz":-480,"elapsed":76694,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"a3b48f30-d31e-4362-8940-e6c0761391d5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 96.09 %\n","Batch 1 averaged accuracy: 97.66 %\n","Batch 2 averaged accuracy: 99.22 %\n","Batch 3 averaged accuracy: 96.09 %\n","Batch 4 averaged accuracy: 96.09 %\n","Batch 5 averaged accuracy: 96.88 %\n","Batch 6 averaged accuracy: 98.44 %\n","Batch 7 averaged accuracy: 97.66 %\n","Batch 8 averaged accuracy: 94.53 %\n","Batch 9 averaged accuracy: 97.66 %\n","Batch 10 averaged accuracy: 97.66 %\n","Batch 11 averaged accuracy: 98.44 %\n","Batch 12 averaged accuracy: 97.66 %\n","Batch 13 averaged accuracy: 100.00 %\n","Batch 14 averaged accuracy: 95.31 %\n","Batch 15 averaged accuracy: 98.44 %\n","Batch 16 averaged accuracy: 98.44 %\n","Batch 17 averaged accuracy: 96.88 %\n","Batch 18 averaged accuracy: 97.66 %\n","Batch 19 averaged accuracy: 97.66 %\n","Batch 20 averaged accuracy: 95.31 %\n","Batch 21 averaged accuracy: 96.88 %\n","Batch 22 averaged accuracy: 96.88 %\n","Batch 23 averaged accuracy: 96.88 %\n","Batch 24 averaged accuracy: 96.88 %\n","\n","Averaged Accuracy: 97.25 %\n"]}]},{"cell_type":"markdown","source":["## Load data and test - 11 users"],"metadata":{"id":"CulIF8a7ZLWI"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU11'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311186092,"user_tz":-480,"elapsed":28,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"3fff68c0-0952-4c92-ef37-a0551f4ed0a5","id":"5aeSzuF6ZkjI"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeCZfJliZuv4","executionInfo":{"status":"ok","timestamp":1712311200498,"user_tz":-480,"elapsed":14432,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"068f2af5-18d2-4866-aa50-8fc733d0323f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 93.75 %\n","Batch 1 averaged accuracy: 97.66 %\n","Batch 2 averaged accuracy: 98.44 %\n","Batch 3 averaged accuracy: 97.66 %\n","\n","Averaged Accuracy: 96.88 %\n"]}]},{"cell_type":"markdown","source":["## Load data and test - 12 users"],"metadata":{"id":"jP521f8-Z4rQ"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU12'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311200810,"user_tz":-480,"elapsed":9,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"24256d6b-e4f1-4cb4-e1ef-ed59ba2cc330","id":"0iczzFT7Z3hO"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311221048,"user_tz":-480,"elapsed":20241,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"d5e9b101-04e2-4dcc-cee4-8723cf9a538f","id":"hrNeyvuDaNIL"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 95.31 %\n","Batch 1 averaged accuracy: 93.75 %\n","Batch 2 averaged accuracy: 94.53 %\n","Batch 3 averaged accuracy: 96.09 %\n","Batch 4 averaged accuracy: 95.31 %\n","Batch 5 averaged accuracy: 95.65 %\n","\n","Averaged Accuracy: 95.11 %\n"]}]},{"cell_type":"markdown","source":["## Load data and test - 13 users"],"metadata":{"id":"OCSpf8dPaAp2"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU13'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311221048,"user_tz":-480,"elapsed":18,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"92655998-9715-42f7-85e0-4085a13bef6a","id":"-NAght_DaYN4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311242167,"user_tz":-480,"elapsed":21135,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"af61d317-3a9a-4b4e-8992-5ee88d2ec490","id":"vWv73WJUawnW"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 95.31 %\n","Batch 1 averaged accuracy: 95.31 %\n","Batch 2 averaged accuracy: 93.75 %\n","Batch 3 averaged accuracy: 96.09 %\n","Batch 4 averaged accuracy: 94.79 %\n","\n","Averaged Accuracy: 95.05 %\n"]}]},{"cell_type":"markdown","source":["## Load data and test - 14 users"],"metadata":{"id":"iNCryvgtaAvs"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU14'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311242167,"user_tz":-480,"elapsed":28,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"b95faf7f-3591-485b-837d-4f7dcb2b9d3a","id":"QSB9tMIeacee"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311265021,"user_tz":-480,"elapsed":22878,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"61dddc1e-ece7-42cf-85f5-985d52249542","id":"9PwtoPEUazwJ"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 96.09 %\n","Batch 1 averaged accuracy: 96.09 %\n","Batch 2 averaged accuracy: 95.31 %\n","Batch 3 averaged accuracy: 96.88 %\n","Batch 4 averaged accuracy: 96.09 %\n","Batch 5 averaged accuracy: 100.00 %\n","\n","Averaged Accuracy: 96.74 %\n"]}]},{"cell_type":"markdown","source":["## Load data and test - 15 users"],"metadata":{"id":"I2fvmx-VaAKO"}},{"cell_type":"code","source":["test_dir = './drive/MyDrive/AcFace_AE/RD-Net/Dataset/Scalability/NU15'\n","\n","batch_size = 128\n","data_test = AudioFaceDataset(test_dir, split='test')\n","data_test_loader = DataLoader(dataset=data_test,\n","                              batch_size=batch_size,\n","                              shuffle=True,\n","                              num_workers=8)\n","\n","print(\"Data loader setup complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311265021,"user_tz":-480,"elapsed":23,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"41079c22-6347-421d-ca28-df472c20248e","id":"sfaj56ZAacv3"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Data loader setup complete.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import time\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n","\n","model.eval()\n","\n","acc_list = []\n","cost_list = []\n","incorrect_samples = []\n","predictions = []\n","true_labels = []\n","\n","for i, (test_X, test_Y, sample_ids) in enumerate(data_test_loader):\n","    face_Y, dist_Y, mask_Y = [], [], []\n","    for Y_i in test_Y:\n","        underline_idx = Y_i.find(\"_\")\n","        face_Y.append(int(Y_i[underline_idx-1]))\n","        dist_Y.append(int(Y_i[underline_idx+1]))\n","        mask_Y.append(int(Y_i[underline_idx+3]))\n","\n","    X = test_X.to(device)\n","    face_Y = torch.LongTensor(face_Y).to(device)\n","    dist_Y = torch.LongTensor(dist_Y).to(device)\n","    mask_Y = torch.LongTensor(mask_Y).to(device)\n","\n","    with torch.no_grad():\n","        output = model(X)\n","\n","        cost_face = criterion(output[0], face_Y)\n","        cost_dist = criterion(output[1], dist_Y)\n","        cost_mask = criterion(output[2], mask_Y)\n","        cost = cost_face - 0.015 * cost_dist - 0.01 * cost_mask\n","\n","        accuracy = (torch.max(output[0], 1)[1] == face_Y).float().mean().item()\n","\n","        acc_list.append(accuracy)\n","        cost_list.append(cost.item())\n","\n","        predictions.extend(torch.max(output[0], 1)[1].cpu().numpy())\n","        true_labels.extend(face_Y.cpu().numpy())\n","\n","        print(f'Batch {i} averaged accuracy: {accuracy*100:.2f} %')\n","\n","        incorrect_predictions = (torch.max(output[0], 1)[1] != face_Y)\n","        incorrect_indices = [i for i, x in enumerate(incorrect_predictions) if x]\n","        incorrect_samples.extend([sample_ids[idx] for idx in incorrect_indices])\n","\n","if acc_list:  # Check if acc_list is not empty\n","    print('\\nAveraged Accuracy: {:2.2f} %'.format(np.mean(acc_list) * 100))\n","else:\n","    raise Exception(\"\\nNo valid accuracy computations were performed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712311289520,"user_tz":-480,"elapsed":24519,"user":{"displayName":"AcFace AE","userId":"08265617518787383570"}},"outputId":"af192ccd-571f-4df2-9fc6-5cd351a67442","id":"rW1s7VBua3W4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch 0 averaged accuracy: 96.88 %\n","Batch 1 averaged accuracy: 96.09 %\n","Batch 2 averaged accuracy: 97.66 %\n","Batch 3 averaged accuracy: 96.09 %\n","Batch 4 averaged accuracy: 94.53 %\n","Batch 5 averaged accuracy: 95.31 %\n","\n","Averaged Accuracy: 96.09 %\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}